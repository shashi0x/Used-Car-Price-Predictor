{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23003ad3",
   "metadata": {},
   "source": [
    "# Making used car price predictor using real world data on a NN\n",
    "I just tried doing this using a linear regression model, but that architecture didn't work well so now i will be making this project on a small Neural Network architexture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81c51cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "188/188 [==============================] - 2s 6ms/step - loss: 6820325228544.0000 - mae: 1156931.6250\n",
      "Epoch 2/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 4268235161600.0000 - mae: 846589.5000\n",
      "Epoch 3/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3918319845376.0000 - mae: 753269.4375\n",
      "Epoch 4/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3698436866048.0000 - mae: 699444.6875\n",
      "Epoch 5/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3466515972096.0000 - mae: 659531.7500\n",
      "Epoch 6/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3380143980544.0000 - mae: 627815.1875\n",
      "Epoch 7/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3321335906304.0000 - mae: 608650.2500\n",
      "Epoch 8/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3208399290368.0000 - mae: 585233.1250\n",
      "Epoch 9/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3154898321408.0000 - mae: 576402.0625\n",
      "Epoch 10/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 3039161221120.0000 - mae: 568252.7500\n",
      "Epoch 11/200\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 3005715841024.0000 - mae: 561011.5625\n",
      "Epoch 12/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2974179131392.0000 - mae: 552291.3750\n",
      "Epoch 13/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2945897201664.0000 - mae: 546623.9375\n",
      "Epoch 14/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2768801628160.0000 - mae: 551322.7500\n",
      "Epoch 15/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2773268561920.0000 - mae: 537433.1875\n",
      "Epoch 16/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2789334056960.0000 - mae: 538742.4375\n",
      "Epoch 17/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2742223896576.0000 - mae: 531946.8750\n",
      "Epoch 18/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2660153163776.0000 - mae: 526726.1875\n",
      "Epoch 19/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2714761166848.0000 - mae: 521429.3750\n",
      "Epoch 20/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2606083342336.0000 - mae: 530558.1875\n",
      "Epoch 21/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2603321131008.0000 - mae: 517706.5000\n",
      "Epoch 22/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2541884276736.0000 - mae: 510348.1562\n",
      "Epoch 23/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2398833082368.0000 - mae: 523443.6250\n",
      "Epoch 24/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2535003258880.0000 - mae: 514179.6250\n",
      "Epoch 25/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2411142578176.0000 - mae: 516324.8125\n",
      "Epoch 26/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2455980998656.0000 - mae: 506331.5312\n",
      "Epoch 27/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2293425504256.0000 - mae: 505761.3125\n",
      "Epoch 28/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2322516934656.0000 - mae: 501034.0625\n",
      "Epoch 29/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2221358972928.0000 - mae: 508962.8438\n",
      "Epoch 30/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2182224412672.0000 - mae: 502195.7500\n",
      "Epoch 31/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2116503470080.0000 - mae: 494615.9688\n",
      "Epoch 32/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2171966717952.0000 - mae: 497354.9688\n",
      "Epoch 33/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 2058483138560.0000 - mae: 489124.6562\n",
      "Epoch 34/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1931481448448.0000 - mae: 492525.3125\n",
      "Epoch 35/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1940029702144.0000 - mae: 484869.6250\n",
      "Epoch 36/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1901122682880.0000 - mae: 477257.8438\n",
      "Epoch 37/200\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1846340354048.0000 - mae: 472764.0312\n",
      "Epoch 38/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1822340677632.0000 - mae: 474374.0312\n",
      "Epoch 39/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1686530949120.0000 - mae: 461821.2812\n",
      "Epoch 40/200\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1751282876416.0000 - mae: 462484.7500\n",
      "Epoch 41/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1555490406400.0000 - mae: 454932.5625\n",
      "Epoch 42/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1541465964544.0000 - mae: 465404.3750\n",
      "Epoch 43/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1483522441216.0000 - mae: 457017.9688\n",
      "Epoch 44/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1389282983936.0000 - mae: 448654.5000\n",
      "Epoch 45/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1549252820992.0000 - mae: 464393.9062\n",
      "Epoch 46/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1350772195328.0000 - mae: 441028.2188\n",
      "Epoch 47/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1307449884672.0000 - mae: 437568.6875\n",
      "Epoch 48/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1501973839872.0000 - mae: 450681.1875\n",
      "Epoch 49/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1298682740736.0000 - mae: 438129.3750\n",
      "Epoch 50/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1300492713984.0000 - mae: 429948.4688\n",
      "Epoch 51/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1350975488000.0000 - mae: 432549.3438\n",
      "Epoch 52/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1307537440768.0000 - mae: 432550.4375\n",
      "Epoch 53/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1288105099264.0000 - mae: 433601.4062\n",
      "Epoch 54/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1212629778432.0000 - mae: 424939.4375\n",
      "Epoch 55/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1119315296256.0000 - mae: 424154.0312\n",
      "Epoch 56/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1325554597888.0000 - mae: 432207.5000\n",
      "Epoch 57/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1260217827328.0000 - mae: 424856.5312\n",
      "Epoch 58/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1139482689536.0000 - mae: 412944.3750\n",
      "Epoch 59/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1346614984704.0000 - mae: 416688.1250\n",
      "Epoch 60/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1026081619968.0000 - mae: 402564.8125\n",
      "Epoch 61/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1176707006464.0000 - mae: 418661.4688\n",
      "Epoch 62/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1082469187584.0000 - mae: 405562.5938\n",
      "Epoch 63/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1142172680192.0000 - mae: 408952.0312\n",
      "Epoch 64/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1131475632128.0000 - mae: 409654.0312\n",
      "Epoch 65/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1095814283264.0000 - mae: 400067.1562\n",
      "Epoch 66/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1081480904704.0000 - mae: 401890.1250\n",
      "Epoch 67/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1095988477952.0000 - mae: 403780.4062\n",
      "Epoch 68/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1037583843328.0000 - mae: 396629.6250\n",
      "Epoch 69/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 907344609280.0000 - mae: 383926.5625\n",
      "Epoch 70/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1206470180864.0000 - mae: 399765.2812\n",
      "Epoch 71/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1104507699200.0000 - mae: 401389.8125\n",
      "Epoch 72/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 922908295168.0000 - mae: 386333.8125\n",
      "Epoch 73/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1007733374976.0000 - mae: 392071.1562\n",
      "Epoch 74/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1076967243776.0000 - mae: 398857.0312\n",
      "Epoch 75/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1004232900608.0000 - mae: 387270.8125\n",
      "Epoch 76/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1000647557120.0000 - mae: 391125.3750\n",
      "Epoch 77/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1000392032256.0000 - mae: 388119.1250\n",
      "Epoch 78/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 962908389376.0000 - mae: 374389.9375\n",
      "Epoch 79/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 953305202688.0000 - mae: 374190.5625\n",
      "Epoch 80/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 985018531840.0000 - mae: 377116.4688\n",
      "Epoch 81/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 901365170176.0000 - mae: 374978.3750\n",
      "Epoch 82/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 911086190592.0000 - mae: 378977.0938\n",
      "Epoch 83/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 912128212992.0000 - mae: 376605.5625\n",
      "Epoch 84/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 961109426176.0000 - mae: 381497.3438\n",
      "Epoch 85/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 857239126016.0000 - mae: 367559.2812\n",
      "Epoch 86/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 1037917749248.0000 - mae: 369215.2812\n",
      "Epoch 87/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 943797305344.0000 - mae: 372320.7188\n",
      "Epoch 88/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 838380224512.0000 - mae: 367935.6562\n",
      "Epoch 89/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 803131752448.0000 - mae: 365915.3125\n",
      "Epoch 90/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 798416437248.0000 - mae: 363511.7188\n",
      "Epoch 91/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 910189527040.0000 - mae: 376248.7188\n",
      "Epoch 92/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 837572689920.0000 - mae: 364807.8438\n",
      "Epoch 93/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 787703070720.0000 - mae: 353629.5625\n",
      "Epoch 94/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 809341747200.0000 - mae: 364930.0625\n",
      "Epoch 95/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 828642295808.0000 - mae: 364943.2188\n",
      "Epoch 96/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 834331017216.0000 - mae: 361740.1250\n",
      "Epoch 97/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 827476082688.0000 - mae: 358487.0938\n",
      "Epoch 98/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 868379066368.0000 - mae: 360037.0000\n",
      "Epoch 99/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 859573256192.0000 - mae: 355460.9062\n",
      "Epoch 100/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 832810516480.0000 - mae: 356353.0312\n",
      "Epoch 101/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 712226504704.0000 - mae: 349961.0000\n",
      "Epoch 102/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 780107251712.0000 - mae: 353042.5000\n",
      "Epoch 103/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 875705597952.0000 - mae: 353081.6562\n",
      "Epoch 104/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 802744958976.0000 - mae: 352690.3125\n",
      "Epoch 105/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 736084885504.0000 - mae: 342046.5000\n",
      "Epoch 106/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 794235437056.0000 - mae: 354031.1562\n",
      "Epoch 107/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 811313135616.0000 - mae: 354056.9375\n",
      "Epoch 108/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 818461409280.0000 - mae: 353937.2812\n",
      "Epoch 109/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 742670860288.0000 - mae: 351334.0312\n",
      "Epoch 110/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 763828109312.0000 - mae: 342770.4688\n",
      "Epoch 111/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 734132240384.0000 - mae: 348620.1875\n",
      "Epoch 112/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 822418669568.0000 - mae: 350106.6875\n",
      "Epoch 113/200\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 732977823744.0000 - mae: 340724.1875\n",
      "Epoch 114/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 734385209344.0000 - mae: 347912.0938\n",
      "Epoch 115/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 724753252352.0000 - mae: 339385.5312\n",
      "Epoch 116/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 742077890560.0000 - mae: 342075.6875\n",
      "Epoch 117/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 727487283200.0000 - mae: 334918.7500\n",
      "Epoch 118/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 704201555968.0000 - mae: 345589.6875\n",
      "Epoch 119/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 721449123840.0000 - mae: 342537.8750\n",
      "Epoch 120/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 702265360384.0000 - mae: 341409.9375\n",
      "Epoch 121/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 826861486080.0000 - mae: 342762.8438\n",
      "Epoch 122/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 755980632064.0000 - mae: 337981.8750\n",
      "Epoch 123/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 647651917824.0000 - mae: 335505.4375\n",
      "Epoch 124/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 690475958272.0000 - mae: 337203.0000\n",
      "Epoch 125/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 677178572800.0000 - mae: 335405.0000\n",
      "Epoch 126/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 699346845696.0000 - mae: 335573.5938\n",
      "Epoch 127/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 729607110656.0000 - mae: 338204.8125\n",
      "Epoch 128/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 708535058432.0000 - mae: 332856.5938\n",
      "Epoch 129/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 699128676352.0000 - mae: 342047.6875\n",
      "Epoch 130/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 717161037824.0000 - mae: 333092.2812\n",
      "Epoch 131/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 641406730240.0000 - mae: 329080.8125\n",
      "Epoch 132/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 663119265792.0000 - mae: 328718.3438\n",
      "Epoch 133/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 667959820288.0000 - mae: 332434.9375\n",
      "Epoch 134/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 711319683072.0000 - mae: 333569.0000\n",
      "Epoch 135/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 715160485888.0000 - mae: 336466.4688\n",
      "Epoch 136/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 708998791168.0000 - mae: 334714.0312\n",
      "Epoch 137/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 714776248320.0000 - mae: 326501.9688\n",
      "Epoch 138/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 620277792768.0000 - mae: 322419.7500\n",
      "Epoch 139/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 884291600384.0000 - mae: 325849.3125\n",
      "Epoch 140/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 627328024576.0000 - mae: 319000.1250\n",
      "Epoch 141/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 680890531840.0000 - mae: 327812.4688\n",
      "Epoch 142/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 618277437440.0000 - mae: 323659.8125\n",
      "Epoch 143/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 708341334016.0000 - mae: 326988.4688\n",
      "Epoch 144/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 635581497344.0000 - mae: 317601.2812\n",
      "Epoch 145/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 658941149184.0000 - mae: 327868.1875\n",
      "Epoch 146/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 674446114816.0000 - mae: 328065.1250\n",
      "Epoch 147/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 625522049024.0000 - mae: 326578.5312\n",
      "Epoch 148/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 713762537472.0000 - mae: 324952.6250\n",
      "Epoch 149/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 611333439488.0000 - mae: 319548.0625\n",
      "Epoch 150/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 699826962432.0000 - mae: 328153.9688\n",
      "Epoch 151/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 668232777728.0000 - mae: 326729.8438\n",
      "Epoch 152/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 599037640704.0000 - mae: 320214.5625\n",
      "Epoch 153/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 669151461376.0000 - mae: 325660.4375\n",
      "Epoch 154/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 689139613696.0000 - mae: 323836.0000\n",
      "Epoch 155/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 609161904128.0000 - mae: 318454.7500\n",
      "Epoch 156/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 566622355456.0000 - mae: 313124.0625\n",
      "Epoch 157/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 671795445760.0000 - mae: 326276.7500\n",
      "Epoch 158/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 669065216000.0000 - mae: 319294.5000\n",
      "Epoch 159/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 642880569344.0000 - mae: 314401.2188\n",
      "Epoch 160/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 661913010176.0000 - mae: 318596.0625\n",
      "Epoch 161/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 596444512256.0000 - mae: 313230.4375\n",
      "Epoch 162/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 681862103040.0000 - mae: 321542.8125\n",
      "Epoch 163/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 714305830912.0000 - mae: 322069.5625\n",
      "Epoch 164/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 599267409920.0000 - mae: 317975.7812\n",
      "Epoch 165/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 560867639296.0000 - mae: 314317.4688\n",
      "Epoch 166/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 685754089472.0000 - mae: 318223.4375\n",
      "Epoch 167/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 560375660544.0000 - mae: 310863.0312\n",
      "Epoch 168/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 703957696512.0000 - mae: 313713.3750\n",
      "Epoch 169/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 624189374464.0000 - mae: 311969.2188\n",
      "Epoch 170/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 609811300352.0000 - mae: 306552.9375\n",
      "Epoch 171/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 599021780992.0000 - mae: 309575.3125\n",
      "Epoch 172/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 591191998464.0000 - mae: 316071.1562\n",
      "Epoch 173/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 615297122304.0000 - mae: 305150.7500\n",
      "Epoch 174/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 597295497216.0000 - mae: 310482.1250\n",
      "Epoch 175/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 574297341952.0000 - mae: 305991.1875\n",
      "Epoch 176/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 610891268096.0000 - mae: 307062.4375\n",
      "Epoch 177/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 565973483520.0000 - mae: 308893.6562\n",
      "Epoch 178/200\n",
      "188/188 [==============================] - 1s 6ms/step - loss: 599064379392.0000 - mae: 305438.2812\n",
      "Epoch 179/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 557328433152.0000 - mae: 307221.9688\n",
      "Epoch 180/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 619268407296.0000 - mae: 307670.6562\n",
      "Epoch 181/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 605486841856.0000 - mae: 309686.9062\n",
      "Epoch 182/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 525738967040.0000 - mae: 305916.1250\n",
      "Epoch 183/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 571166162944.0000 - mae: 300721.2188\n",
      "Epoch 184/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 530697650176.0000 - mae: 306026.1562\n",
      "Epoch 185/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 553676636160.0000 - mae: 300996.8750\n",
      "Epoch 186/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 560184295424.0000 - mae: 304164.1562\n",
      "Epoch 187/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 550957088768.0000 - mae: 298306.9375\n",
      "Epoch 188/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 497842290688.0000 - mae: 302645.3438\n",
      "Epoch 189/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 624503226368.0000 - mae: 310449.0625\n",
      "Epoch 190/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 551624835072.0000 - mae: 300094.0938\n",
      "Epoch 191/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 536201035776.0000 - mae: 303673.5938\n",
      "Epoch 192/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 525139378176.0000 - mae: 299407.5625\n",
      "Epoch 193/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 558884913152.0000 - mae: 301408.9375\n",
      "Epoch 194/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 548842962944.0000 - mae: 295317.6875\n",
      "Epoch 195/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 613020729344.0000 - mae: 303296.7188\n",
      "Epoch 196/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 582443401216.0000 - mae: 294868.9062\n",
      "Epoch 197/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 548773429248.0000 - mae: 298135.4375\n",
      "Epoch 198/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 617064038400.0000 - mae: 302379.9375\n",
      "Epoch 199/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 473357123584.0000 - mae: 288743.2500\n",
      "Epoch 200/200\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 510188814336.0000 - mae: 291425.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2766edff0d0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=512, activation='relu'),\n",
    "    Dense(units=256, activation='relu'),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=1, activation='linear')\n",
    "])\n",
    "model.compile(loss='mse', metrics='mae')\n",
    "df = pd.read_csv('CleanDataNP.csv')\n",
    "shuffledData = df.to_numpy()\n",
    "np.random.shuffle(shuffledData)\n",
    "rX = shuffledData[:,0:-1]\n",
    "rY = shuffledData[:,-1]\n",
    "\n",
    "#dividing data into two parts: training set (X, Y) and then test set (tX, tY)\n",
    "X, Y = rX[:6000, :], rY[:6000].reshape(-1, 1).astype(np.float32)\n",
    "tX, tY = rX[6000:, :], rY[6000:].reshape(-1, 1).astype(np.float32)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "model.fit(X_scaled, Y, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f8a746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 2ms/step\n",
      "85/85 [==============================] - 0s 2ms/step\n",
      "unseenMAE: 368877.5\n",
      "seenMAE: 323231.38\n"
     ]
    }
   ],
   "source": [
    "syi = model.predict(X_scaled)\n",
    "tx_scaled = scaler.transform(tX)\n",
    "uyi = model.predict(tx_scaled)\n",
    "unseenMAE = np.mean(np.abs(uyi - tY))\n",
    "seenMAE = np.mean(np.abs(syi - Y))\n",
    "print(\"unseenMAE:\", unseenMAE)\n",
    "print(\"seenMAE:\", seenMAE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
