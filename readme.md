# Used Car Price Prediction

## Overview

This project focuses on predicting the prices of used cars by building an end-to-end **data pipeline** and **machine learning model** trained on real-world listings scraped from [CarWale](https://www.carwale.com/).  
The workflow includes **web scraping**, **data preprocessing**, **feature engineering**, and **deep learning** model training.

---

## Project Structure

OLDCAR  
â”‚  
â”œâ”€â”€ data  
â”‚ â”œâ”€â”€ CarData.csv # Raw scraped data  
â”‚ â”œâ”€â”€ carwale.html # Sample HTML page  
â”‚ â”œâ”€â”€ CleanDataNP.csv # Processed numeric dataset  
â”‚ â”œâ”€â”€ dataReadme.md # Data documentation  
â”‚ â”œâ”€â”€ jsonEx.json # Extracted JSON sample  
â”‚ â””â”€â”€ scrapping.ipynb # Web scraping + data collection  
â”‚  
â”œâ”€â”€ model  
â”‚ |â”€â”€ CleanDataNP.csv # Final preprocessed dataset  
â”‚ â”œâ”€â”€ linear.ipynb # Linear regression attempt  
â”‚ â””â”€â”€ neural.ipynb # Neural network model  
â”œâ”€â”€ readme.md


## Dataset

- **Source:** Scraped from CarWaleâ€™s used car listings across **350+ Indian cities**.  
- **Size:** 8,718 examples.  
- **Collection Method:**  
  - Extracted car listing details from JSON objects embedded in `<script>` tags.  
  - For diversity, 30 listings were scraped from each cityâ€™s page instead of paginating deeper.  

### Dataset Statistics

- **Training set:** 6,000 examples  
- **Test set:** 2,718 examples  
- **Mean Price:** â‚¹19,15,637  
- **Median Price:** â‚¹8,00,000  
- **Min Price:** â‚¹25,000  
- **Max Price:** â‚¹4,21,00,000  
- **Std Dev:** â‚¹31,13,977  

---

## Data Preprocessing

- Extracted raw data (HTML â†’ JSON â†’ CSV).  
- Handled categorical variables by encoding them into numeric values (e.g., body type, transmission type).  
- Applied **scaling** for numerical stability.  
- Converted dataset to **NumPy arrays** for training.  

---

## ðŸŽ¯ Features & Target

- **Input Features (X):**
  - `age` â†’ Age of the car (years)  
  - `brand` â†’ Encoded brand name  
  - `kmdriven` â†’ Kilometers driven  
  - `fuelType` â†’ Fuel type (Petrol/Diesel/CNG/Electric etc.)  
  - `bodyType` â†’ Car body type (SUV, Sedan, Hatchback, etc.)  
  - `seatCap` â†’ Seating capacity  
  - `transmission` â†’ Transmission type (Manual/Automatic etc.)  
  - `owners` â†’ Number of previous owners  

- **Target (Y):**
  - `price` â†’ Final resale price of the car  

---

## Modeling

### 1. Linear Regression (Baseline)

- Tried linear regression first.  
- Model failed to capture complex relationships in data.  

### 2. Neural Network (Final Model)

Implemented using **TensorFlow/Keras**:

```python
model = Sequential([
    Dense(64, activation='relu'),
    Dense(128, activation='relu'),
    Dense(256, activation='relu'),
    Dense(512, activation='relu'),
    Dense(256, activation='relu'),
    Dense(128, activation='relu'),
    Dense(64, activation='relu'),
    Dense(1, activation='linear')
])
```

## Results & Conclusion

* Seen Data MAE: â‚¹3,23,231

* Unseen Data MAE: â‚¹3,68,877

* While the MAE is still high, it is reasonable given the dataset includes both budget cars and ultra-luxury cars (â‚¹25,000 to â‚¹4.2 Cr range).

* A single model struggles because predicting a Swift and a BMW i7 with the same function is naturally imbalanced.

* Key learning: Instead of training one global model, grouping cars (e.g., budget, mid-range, luxury) and training separate models would likely yield better accuracy.


#### This demonstrates an important ML lesson: sometimes data segmentation and domain knowledge can be more impactful than just tuning architectures.


## Tech Stack

* Language: Python

* Libraries: NumPy, Pandas, Requests, BeautifulSoup, JSON, TensorFlow/Keras

## Learnings

* Designing and implementing a web scraper for structured data collection.

* Parsing and extracting data from embedded JSON objects.

* Applying feature engineering (categorical encoding + scaling).

* Comparing baseline ML (Linear Regression) vs Deep Learning.

* Understanding dataset imbalance and how it affects ML model performance.

## Future Work

* Split dataset into groups (budget / premium / luxury) and train specialized models.

* Improve preprocessing with outlier detection and feature importance analysis.

* Experiment with alternative models (XGBoost, Random Forest, or even hybrid ensembles).

* Build a simple deployment interface (API or Streamlit app).

## Author

### Shashi Kumar

**Student | Exploring AI/ML | Interested in practical applications of Machine Learning**
